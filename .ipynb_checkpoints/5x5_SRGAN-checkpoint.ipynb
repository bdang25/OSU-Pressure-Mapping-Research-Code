{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 510 images in the 'images_32x32' folder after removing rows with all zero values.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"soren.csv\"  # Ensure this path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(['Frame', 'Timestamp', 'Average Pressure (mmHg)', 'Minimum Pressure (mmHg)', \n",
    "           'Maximum Pressure (mmHg)', 'Standard Pressure Deviation (mmHg)', \n",
    "           'Median Pressure (mmHg)', 'Contact Area (m²)', 'Total Area (m²)', \n",
    "           'Estimated Force (N)', 'Range Min (mmHg)', 'Range Max (mmHg)'], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with all zero values\n",
    "data = data[(data != 0).any(axis=1)]\n",
    "\n",
    "# Create a directory to save the images\n",
    "output_folder = \"images_32x32\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "# Loop through each row in the dataset and save it as a 32x32 image\n",
    "for i in range(num_rows):\n",
    "    # Reshape the data into a 32x32 grid\n",
    "    grid_data = data.iloc[i].values.reshape(32, 32)\n",
    "    \n",
    "    # Create a plot without axis\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(grid_data, cmap='viridis', interpolation='none')\n",
    "    plt.axis('off')  # Remove axis\n",
    "    \n",
    "    # Save the image in the output folder\n",
    "    image_filename = os.path.join(output_folder, f\"pressure_image_{i+1}.png\")\n",
    "    plt.savefig(image_filename, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {num_rows} images in the '{output_folder}' folder after removing rows with all zero values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 510 5x5 images in the 'images_5x5' folder after processing the original data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"soren.csv\"  # Ensure this path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(['Frame', 'Timestamp', 'Average Pressure (mmHg)', 'Minimum Pressure (mmHg)', \n",
    "           'Maximum Pressure (mmHg)', 'Standard Pressure Deviation (mmHg)', \n",
    "           'Median Pressure (mmHg)', 'Contact Area (m²)', 'Total Area (m²)', \n",
    "           'Estimated Force (N)', 'Range Min (mmHg)', 'Range Max (mmHg)'], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with all zero values\n",
    "data = data[(data != 0).any(axis=1)]\n",
    "\n",
    "# Create a directory to save the 7x7 images\n",
    "output_folder_7x7 = \"images_5x5\"\n",
    "os.makedirs(output_folder_7x7, exist_ok=True)\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "# Loop through each row in the dataset and save it as a 7x7 image\n",
    "for i in range(num_rows):\n",
    "    # Reshape the data into a 32x32 grid\n",
    "    grid_data = data.iloc[i].values.reshape(32, 32)\n",
    "    \n",
    "    # # Select the values to form a 7x7 grid starting from (2, 2) and taking every 4th square\n",
    "    # selected_indices = [(2 + j * 4, 2 + k * 4) for j in range(7) for k in range(7)]\n",
    "    # reduced_grid_data = np.array([[grid_data[x, y] for x, y in selected_indices[j*7:(j+1)*7]] for j in range(7)])\n",
    "    indices = np.linspace(1, 32, 7, dtype=int)  # This gives edge points and middle points\n",
    "\n",
    "    # Select only the 5 middle points (2nd to 6th)\n",
    "    selected_indices = [(indices[j], indices[k]) for j in range(1, 6) for k in range(1, 6)]\n",
    "\n",
    "    # Create the reduced grid by picking only the selected points\n",
    "    reduced_grid_data = np.array([[grid_data[x, y] for x, y in selected_indices[j*5:(j+1)*5]] for j in range(5)])\n",
    "    # Create a plot without axis\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(reduced_grid_data, cmap='viridis', interpolation='none')\n",
    "    plt.axis('off')  # Remove axis\n",
    "    \n",
    "    # Save the image in the output folder\n",
    "    image_filename_7x7 = os.path.join(output_folder_7x7, f\"pressure_image_5x5_{i+1}.png\")\n",
    "    plt.savefig(image_filename_7x7, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {num_rows} 5x5 images in the '{output_folder_7x7}' folder after processing the original data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], D Loss: 1.6463, G Loss: 1.8206\n",
      "Epoch [2/100], D Loss: 1.1767, G Loss: 1.2364\n",
      "Epoch [3/100], D Loss: 0.5632, G Loss: 1.4801\n",
      "Epoch [4/100], D Loss: 1.0441, G Loss: 1.3318\n",
      "Epoch [5/100], D Loss: 0.5994, G Loss: 1.1545\n",
      "Epoch [6/100], D Loss: 1.2129, G Loss: 0.6872\n",
      "Epoch [7/100], D Loss: 0.3323, G Loss: 2.5914\n",
      "Epoch [8/100], D Loss: 1.8003, G Loss: 0.3744\n",
      "Epoch [9/100], D Loss: 0.6851, G Loss: 1.8075\n",
      "Epoch [10/100], D Loss: 0.2769, G Loss: 4.1377\n",
      "Epoch [11/100], D Loss: 1.8805, G Loss: 0.8570\n",
      "Epoch [12/100], D Loss: 1.3689, G Loss: 1.1194\n",
      "Epoch [13/100], D Loss: 1.0620, G Loss: 3.3985\n",
      "Epoch [14/100], D Loss: 1.2688, G Loss: 1.0370\n",
      "Epoch [15/100], D Loss: 1.3806, G Loss: 0.8517\n",
      "Epoch [16/100], D Loss: 2.1981, G Loss: 0.4436\n",
      "Epoch [17/100], D Loss: 1.4312, G Loss: 0.7040\n",
      "Epoch [18/100], D Loss: 1.3072, G Loss: 0.9198\n",
      "Epoch [19/100], D Loss: 0.1232, G Loss: 4.0932\n",
      "Epoch [20/100], D Loss: 1.3547, G Loss: 0.9811\n",
      "Epoch [21/100], D Loss: 1.1394, G Loss: 0.9947\n",
      "Epoch [22/100], D Loss: 1.2955, G Loss: 1.1308\n",
      "Epoch [23/100], D Loss: 1.1781, G Loss: 1.2154\n",
      "Epoch [24/100], D Loss: 1.2199, G Loss: 1.1417\n",
      "Epoch [25/100], D Loss: 1.1783, G Loss: 0.9849\n",
      "Epoch [26/100], D Loss: 0.8679, G Loss: 1.3994\n",
      "Epoch [27/100], D Loss: 0.5553, G Loss: 2.5994\n",
      "Epoch [28/100], D Loss: 1.2161, G Loss: 1.2892\n",
      "Epoch [29/100], D Loss: 1.1687, G Loss: 1.4671\n",
      "Epoch [30/100], D Loss: 1.1989, G Loss: 1.2169\n",
      "Epoch [31/100], D Loss: 0.5281, G Loss: 4.6869\n",
      "Epoch [32/100], D Loss: 1.2113, G Loss: 1.3637\n",
      "Epoch [33/100], D Loss: 0.5802, G Loss: 2.7526\n",
      "Epoch [34/100], D Loss: 1.2604, G Loss: 0.9991\n",
      "Epoch [35/100], D Loss: 1.1919, G Loss: 1.5347\n",
      "Epoch [36/100], D Loss: 1.0507, G Loss: 1.4086\n",
      "Epoch [37/100], D Loss: 1.0490, G Loss: 1.5973\n",
      "Epoch [38/100], D Loss: 1.7009, G Loss: 1.2384\n",
      "Epoch [39/100], D Loss: 0.9538, G Loss: 0.9933\n",
      "Epoch [40/100], D Loss: 1.6856, G Loss: 0.5148\n",
      "Epoch [41/100], D Loss: 1.3440, G Loss: 0.8230\n",
      "Epoch [42/100], D Loss: 0.8459, G Loss: 2.6454\n",
      "Epoch [43/100], D Loss: 0.9953, G Loss: 1.5072\n",
      "Epoch [44/100], D Loss: 0.2359, G Loss: 4.7155\n",
      "Epoch [45/100], D Loss: 0.7948, G Loss: 1.7797\n",
      "Epoch [46/100], D Loss: 0.2452, G Loss: 6.0193\n",
      "Epoch [47/100], D Loss: 0.5651, G Loss: 3.0915\n",
      "Epoch [48/100], D Loss: 0.9824, G Loss: 1.1196\n",
      "Epoch [49/100], D Loss: 1.0031, G Loss: 0.9547\n",
      "Epoch [50/100], D Loss: 0.1536, G Loss: 6.4521\n",
      "Epoch [51/100], D Loss: 0.8417, G Loss: 7.2485\n",
      "Epoch [52/100], D Loss: 1.3177, G Loss: 0.9944\n",
      "Epoch [53/100], D Loss: 1.8775, G Loss: 0.3804\n",
      "Epoch [54/100], D Loss: 3.1708, G Loss: 1.1231\n",
      "Epoch [55/100], D Loss: 1.8051, G Loss: 0.5213\n",
      "Epoch [56/100], D Loss: 1.9179, G Loss: 0.6375\n",
      "Epoch [57/100], D Loss: 0.2374, G Loss: 5.9731\n",
      "Epoch [58/100], D Loss: 0.6987, G Loss: 3.7446\n",
      "Epoch [59/100], D Loss: 1.1767, G Loss: 1.1407\n",
      "Epoch [60/100], D Loss: 0.8530, G Loss: 5.7753\n",
      "Epoch [61/100], D Loss: 0.1338, G Loss: 13.0492\n",
      "Epoch [62/100], D Loss: 0.5026, G Loss: 6.8598\n",
      "Epoch [63/100], D Loss: 1.1346, G Loss: 1.0966\n",
      "Epoch [64/100], D Loss: 1.3901, G Loss: 1.0698\n",
      "Epoch [65/100], D Loss: 0.3032, G Loss: 3.1119\n",
      "Epoch [66/100], D Loss: 1.3878, G Loss: 0.6856\n",
      "Epoch [67/100], D Loss: 0.9115, G Loss: 2.3164\n",
      "Epoch [68/100], D Loss: 0.2454, G Loss: 7.3290\n",
      "Epoch [69/100], D Loss: 0.7099, G Loss: 0.7274\n",
      "Epoch [70/100], D Loss: 0.1835, G Loss: 7.1264\n",
      "Epoch [71/100], D Loss: 0.5927, G Loss: 4.8594\n",
      "Epoch [72/100], D Loss: 0.1750, G Loss: 6.8362\n",
      "Epoch [73/100], D Loss: 0.4648, G Loss: 2.1552\n",
      "Epoch [74/100], D Loss: 0.2623, G Loss: 5.9383\n",
      "Epoch [75/100], D Loss: 0.2013, G Loss: 8.6184\n",
      "Epoch [76/100], D Loss: 1.4585, G Loss: 0.5114\n",
      "Epoch [77/100], D Loss: 0.6701, G Loss: 1.7304\n",
      "Epoch [78/100], D Loss: 0.8727, G Loss: 1.2228\n",
      "Epoch [79/100], D Loss: 0.7503, G Loss: 1.5133\n",
      "Epoch [80/100], D Loss: 0.7085, G Loss: 1.9292\n",
      "Epoch [81/100], D Loss: 0.8821, G Loss: 1.4099\n",
      "Epoch [82/100], D Loss: 0.6900, G Loss: 1.7786\n",
      "Epoch [83/100], D Loss: 0.6905, G Loss: 1.6383\n",
      "Epoch [84/100], D Loss: 0.5220, G Loss: 2.5068\n",
      "Epoch [85/100], D Loss: 0.8398, G Loss: 2.4313\n",
      "Epoch [86/100], D Loss: 0.8404, G Loss: 1.6630\n",
      "Epoch [87/100], D Loss: 0.7260, G Loss: 1.6412\n",
      "Epoch [88/100], D Loss: 0.8737, G Loss: 1.2520\n",
      "Epoch [89/100], D Loss: 0.6443, G Loss: 1.4909\n",
      "Epoch [90/100], D Loss: 1.0112, G Loss: 1.2668\n",
      "Epoch [91/100], D Loss: 0.7264, G Loss: 1.4129\n",
      "Epoch [92/100], D Loss: 0.8406, G Loss: 2.1604\n",
      "Epoch [93/100], D Loss: 0.7415, G Loss: 2.1544\n",
      "Epoch [94/100], D Loss: 0.4578, G Loss: 2.8006\n",
      "Epoch [95/100], D Loss: 0.8626, G Loss: 2.9887\n",
      "Epoch [96/100], D Loss: 0.7763, G Loss: 2.0081\n",
      "Epoch [97/100], D Loss: 0.6630, G Loss: 1.6262\n",
      "Epoch [98/100], D Loss: 0.8055, G Loss: 1.8838\n",
      "Epoch [99/100], D Loss: 0.8710, G Loss: 1.8712\n",
      "Epoch [100/100], D Loss: 0.2976, G Loss: 6.5232\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Prepare Data\n",
    "def prepare_data(folder_path, image_size=(32, 32)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img = plt.imread(os.path.join(folder_path, filename))\n",
    "            # Ensure the image has 3 channels\n",
    "            if img.shape[-1] == 4:  # Check for alpha channel\n",
    "                img = img[..., :3]  # Discard the alpha channel\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Resize(image_size)(img)  # Resize to 32x32\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "# Paths\n",
    "folder_5x5 = 'images_5x5'\n",
    "folder_32x32 = 'images_32x32'\n",
    "save_models_folder = 'saved_models'\n",
    "os.makedirs(save_models_folder, exist_ok=True)\n",
    "\n",
    "# Load Data\n",
    "low_res_images = prepare_data(folder_5x5)\n",
    "high_res_images = prepare_data(folder_32x32)\n",
    "\n",
    "# Model Setup\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(low_res_images)):\n",
    "        low_res = low_res_images[i].unsqueeze(0)  # Add batch dimension\n",
    "        high_res = high_res_images[i].unsqueeze(0)\n",
    "\n",
    "        # Create labels to match the output of the discriminator\n",
    "        real_label = torch.ones((1, 1, 4, 4))  # Real label (change size to [1, 1, 4, 4])\n",
    "        fake_label = torch.zeros((1, 1, 4, 4))  # Fake label (change size to [1, 1, 4, 4])\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(high_res)\n",
    "        d_loss_real = criterion(outputs, real_label)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        fake_image = generator(low_res)\n",
    "        outputs = discriminator(fake_image.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_label)\n",
    "        d_loss_fake.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_image)\n",
    "        g_loss = criterion(outputs, real_label)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], D Loss: {d_loss_real.item() + d_loss_fake.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "    \n",
    "    # Save the generator and discriminator models\n",
    "    torch.save(generator.state_dict(), os.path.join(save_models_folder, 'generator.pth'))\n",
    "    torch.save(discriminator.state_dict(), os.path.join(save_models_folder, 'discriminator.pth'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Load the trained generator\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mgenerator\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_models_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Test the model on image 155\u001b[39;00m\n\u001b[0;32m     57\u001b[0m test_model_on_image(generator, low_res_images, high_res_images, image_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m155\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Updated Testing Function for a specific image (image 155)\n",
    "def test_model_on_image(generator, low_res_images, high_res_images, image_index=155):\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the low-res and high-res images for the specified index\n",
    "        low_res = low_res_images[image_index].unsqueeze(0)\n",
    "        fake_image = generator(low_res).squeeze().cpu().numpy()\n",
    "        real_image = high_res_images[image_index].squeeze().cpu().numpy()\n",
    "        low_res_image = low_res.squeeze().cpu().numpy()\n",
    "\n",
    "        # If the images have 3 channels, convert them to grayscale by averaging the channels\n",
    "        if low_res_image.ndim == 3:\n",
    "            low_res_image = low_res_image.mean(axis=0)  # Convert to grayscale\n",
    "        if fake_image.ndim == 3:\n",
    "            fake_image = fake_image.mean(axis=0)  # Convert to grayscale\n",
    "        if real_image.ndim == 3:\n",
    "            real_image = real_image.mean(axis=0)  # Convert to grayscale\n",
    "\n",
    "        # Calculate PSNR and RMSE\n",
    "        psnr_value = psnr(real_image, fake_image)\n",
    "        rmse_value = np.sqrt(mse(real_image, fake_image))\n",
    "\n",
    "        print(f'PSNR for image {image_index}: {psnr_value:.2f}')\n",
    "        print(f'RMSE for image {image_index}: {rmse_value:.4f}')\n",
    "\n",
    "        # Plot the low-res, real high-res, and generated high-res images\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # Low-res image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(low_res_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Low-Res Image (5x5)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Real high-res image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(real_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Real High-Res Image (32x32)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Generated high-res image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(fake_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Generated High-Res Image (32x32)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Load the trained generator\n",
    "generator.load_state_dict(torch.load(os.path.join(save_models_folder, 'generator.pth')))\n",
    "\n",
    "# Test the model on image 155\n",
    "test_model_on_image(generator, low_res_images, high_res_images, image_index=155)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Test the model on image 155 with kriging interpolation\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[43mtest_model_on_image_with_kriging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_res_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh_res_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m155\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 52\u001b[0m, in \u001b[0;36mtest_model_on_image_with_kriging\u001b[1;34m(generator, low_res_images, high_res_images, image_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m low_res_kriged \u001b[38;5;241m=\u001b[39m kriging_interpolation(low_res_image, (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Perform kriging on the high-res images to interpolate to 256x256\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m fake_image_kriged \u001b[38;5;241m=\u001b[39m \u001b[43mkriging_interpolation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m real_image_kriged \u001b[38;5;241m=\u001b[39m kriging_interpolation(real_image, (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Calculate PSNR and RMSE between the kriged real image and generated image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m, in \u001b[0;36mkriging_interpolation\u001b[1;34m(image, new_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Perform kriging interpolation\u001b[39;00m\n\u001b[0;32m     24\u001b[0m krig \u001b[38;5;241m=\u001b[39m OrdinaryKriging(xx_current\u001b[38;5;241m.\u001b[39mflatten(), yy_current\u001b[38;5;241m.\u001b[39mflatten(), values, variogram_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m interpolated_image, _ \u001b[38;5;241m=\u001b[39m \u001b[43mkrig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m interpolated_image\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pykrige\\ok.py:999\u001b[0m, in \u001b[0;36mOrdinaryKriging.execute\u001b[1;34m(self, style, xpoints, ypoints, mask, backend, n_closest_points)\u001b[0m\n\u001b[0;32m    991\u001b[0m     bd \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mgreat_circle_distance(\n\u001b[0;32m    992\u001b[0m         xpts[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[0;32m    993\u001b[0m         ypts[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_ADJUSTED,\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_ADJUSTED,\n\u001b[0;32m    996\u001b[0m     )\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 999\u001b[0m     zvalues, sigmasq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloop\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1001\u001b[0m     zvalues, sigmasq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_loop(a, bd, mask)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pykrige\\ok.py:681\u001b[0m, in \u001b[0;36mOrdinaryKriging._exec_vector\u001b[1;34m(self, a, bd, mask)\u001b[0m\n\u001b[0;32m    679\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a_inv, b\u001b[38;5;241m.\u001b[39mreshape((npt, n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, npt))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    680\u001b[0m zvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(x[:, :n, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 681\u001b[0m sigmasq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m zvalues, sigmasq\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:4339\u001b[0m, in \u001b[0;36mMaskedArray.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   4337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate_binop(other):\n\u001b[0;32m   4338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 4339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:1054\u001b[0m, in \u001b[0;36m_MaskedBinaryOperation.__call__\u001b[1;34m(self, a, b, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate():\n\u001b[0;32m   1053\u001b[0m     np\u001b[38;5;241m.\u001b[39mseterr(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1054\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# Get the mask for the result\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m (ma, mb) \u001b[38;5;241m=\u001b[39m (getmask(a), getmask(b))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform kriging on an image and interpolate it to a desired resolution\n",
    "def kriging_interpolation(image, new_size):\n",
    "    # Get the current size of the image\n",
    "    current_size = image.shape\n",
    "\n",
    "    # Create grid points for the current image size\n",
    "    x_current = np.linspace(0, current_size[0] - 1, current_size[0])\n",
    "    y_current = np.linspace(0, current_size[1] - 1, current_size[1])\n",
    "    xx_current, yy_current = np.meshgrid(x_current, y_current)\n",
    "\n",
    "    # Flatten the grid and image data\n",
    "    points = np.vstack((xx_current.flatten(), yy_current.flatten())).T\n",
    "    values = image.flatten()\n",
    "\n",
    "    # Create new grid points for the target size\n",
    "    x_new = np.linspace(0, current_size[0] - 1, new_size[0])\n",
    "    y_new = np.linspace(0, current_size[1] - 1, new_size[1])\n",
    "    xx_new, yy_new = np.meshgrid(x_new, y_new)\n",
    "\n",
    "    # Perform kriging interpolation\n",
    "    krig = OrdinaryKriging(xx_current.flatten(), yy_current.flatten(), values, variogram_model='linear')\n",
    "    interpolated_image, _ = krig.execute('grid', x_new, y_new)\n",
    "\n",
    "    return interpolated_image.T  # Transpose to match the original image orientation\n",
    "\n",
    "# Updated Testing Function with Kriging interpolation for specific image (image 155)\n",
    "def test_model_on_image_with_kriging(generator, low_res_images, high_res_images, image_index=155):\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the low-res and high-res images for the specified index\n",
    "        low_res = low_res_images[image_index].unsqueeze(0)\n",
    "        fake_image = generator(low_res).squeeze().cpu().numpy()\n",
    "        real_image = high_res_images[image_index].squeeze().cpu().numpy()\n",
    "        low_res_image = low_res.squeeze().cpu().numpy()\n",
    "\n",
    "        # If the images have 3 channels, convert them to grayscale by averaging the channels\n",
    "        if low_res_image.ndim == 3:\n",
    "            low_res_image = low_res_image.mean(axis=0)  # Convert to grayscale\n",
    "        if fake_image.ndim == 3:\n",
    "            fake_image = fake_image.mean(axis=0)  # Convert to grayscale\n",
    "        if real_image.ndim == 3:\n",
    "            real_image = real_image.mean(axis=0)  # Convert to grayscale\n",
    "\n",
    "        # Perform kriging on the low-res image to interpolate it to 64x64\n",
    "        low_res_kriged = kriging_interpolation(low_res_image, (64, 64))\n",
    "\n",
    "        # Perform kriging on the high-res images to interpolate to 256x256\n",
    "        fake_image_kriged = kriging_interpolation(fake_image, (256, 256))\n",
    "        real_image_kriged = kriging_interpolation(real_image, (256, 256))\n",
    "\n",
    "        # Calculate PSNR and RMSE between the kriged real image and generated image\n",
    "        psnr_value = psnr(real_image_kriged, fake_image_kriged)\n",
    "        rmse_value = np.sqrt(mse(real_image_kriged, fake_image_kriged))\n",
    "\n",
    "        print(f'PSNR for image {image_index} (Kriged): {psnr_value:.2f}')\n",
    "        print(f'RMSE for image {image_index} (Kriged): {rmse_value:.4f}')\n",
    "\n",
    "        # Plot the kriged low-res, real high-res, and generated high-res images\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Kriged low-res image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(low_res_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Low-Res Image (5x5 Kriged to 64x64)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Kriged real high-res image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(real_image_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Real High-Res Image (32x32 Kriged to 256x256)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Kriged generated high-res image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(fake_image_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Generated High-Res Image (32x32 Kriged to 256x256)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test the model on image 155 with kriging interpolation\n",
    "test_model_on_image_with_kriging(generator, low_res_images, high_res_images, image_index=155)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
