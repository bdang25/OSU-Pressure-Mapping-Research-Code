{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 510 images in the 'images_32x32' folder after removing rows with all zero values.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"soren.csv\"  # Ensure this path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(['Frame', 'Timestamp', 'Average Pressure (mmHg)', 'Minimum Pressure (mmHg)', \n",
    "           'Maximum Pressure (mmHg)', 'Standard Pressure Deviation (mmHg)', \n",
    "           'Median Pressure (mmHg)', 'Contact Area (m²)', 'Total Area (m²)', \n",
    "           'Estimated Force (N)', 'Range Min (mmHg)', 'Range Max (mmHg)'], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with all zero values\n",
    "data = data[(data != 0).any(axis=1)]\n",
    "\n",
    "# Create a directory to save the images\n",
    "output_folder = \"images_32x32\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "# Loop through each row in the dataset and save it as a 32x32 image\n",
    "for i in range(num_rows):\n",
    "    # Reshape the data into a 32x32 grid\n",
    "    grid_data = data.iloc[i].values.reshape(32, 32)\n",
    "    \n",
    "    # Create a plot without axis\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(grid_data, cmap='viridis', interpolation='none')\n",
    "    plt.axis('off')  # Remove axis\n",
    "    \n",
    "    # Save the image in the output folder\n",
    "    image_filename = os.path.join(output_folder, f\"pressure_image_{i+1}.png\")\n",
    "    plt.savefig(image_filename, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {num_rows} images in the '{output_folder}' folder after removing rows with all zero values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 510 5x5 images in the 'images_5x5' folder after processing the original data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"soren.csv\"  # Ensure this path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data.drop(['Frame', 'Timestamp', 'Average Pressure (mmHg)', 'Minimum Pressure (mmHg)', \n",
    "           'Maximum Pressure (mmHg)', 'Standard Pressure Deviation (mmHg)', \n",
    "           'Median Pressure (mmHg)', 'Contact Area (m²)', 'Total Area (m²)', \n",
    "           'Estimated Force (N)', 'Range Min (mmHg)', 'Range Max (mmHg)'], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with all zero values\n",
    "data = data[(data != 0).any(axis=1)]\n",
    "\n",
    "# Create a directory to save the 7x7 images\n",
    "output_folder_7x7 = \"images_5x5\"\n",
    "os.makedirs(output_folder_7x7, exist_ok=True)\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "# Loop through each row in the dataset and save it as a 7x7 image\n",
    "for i in range(num_rows):\n",
    "    # Reshape the data into a 32x32 grid\n",
    "    grid_data = data.iloc[i].values.reshape(32, 32)\n",
    "    \n",
    "    # # Select the values to form a 7x7 grid starting from (2, 2) and taking every 4th square\n",
    "    #selected_indices = [(2 + j * 4, 2 + k * 4) for j in range(7) for k in range(7)]\n",
    "    #reduced_grid_data = np.array([[grid_data[x, y] for x, y in selected_indices[j*7:(j+1)*7]] for j in range(7)])\n",
    "    indices = np.linspace(1, 32, 7, dtype=int)  # This gives edge points and middle points\n",
    "\n",
    "    # Select only the 5 middle points (2nd to 6th)\n",
    "    selected_indices = [(indices[j], indices[k]) for j in range(1, 6) for k in range(1, 6)]\n",
    "\n",
    "    # Create the reduced grid by picking only the selected points\n",
    "    reduced_grid_data = np.array([[grid_data[x, y] for x, y in selected_indices[j*5:(j+1)*5]] for j in range(5)])\n",
    "    # Create a plot without axis\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(reduced_grid_data, cmap='viridis', interpolation='none')\n",
    "    plt.axis('off')  # Remove axis\n",
    "    \n",
    "    # Save the image in the output folder\n",
    "    image_filename_7x7 = os.path.join(output_folder_7x7, f\"pressure_image_5x5_{i+1}.png\")\n",
    "    plt.savefig(image_filename_7x7, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {num_rows} 5x5 images in the '{output_folder_7x7}' folder after processing the original data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], D Loss: 1.3549, G Loss: 1.2687\n",
      "Epoch [2/100], D Loss: 1.3779, G Loss: 0.6546\n",
      "Epoch [3/100], D Loss: 1.0192, G Loss: 1.1273\n",
      "Epoch [4/100], D Loss: 1.3189, G Loss: 0.7523\n",
      "Epoch [5/100], D Loss: 0.2863, G Loss: 1.9715\n",
      "Epoch [6/100], D Loss: 0.4953, G Loss: 3.7864\n",
      "Epoch [7/100], D Loss: 0.5375, G Loss: 1.8461\n",
      "Epoch [8/100], D Loss: 1.1532, G Loss: 1.0755\n",
      "Epoch [9/100], D Loss: 0.5662, G Loss: 1.1792\n",
      "Epoch [10/100], D Loss: 0.4496, G Loss: 1.5984\n",
      "Epoch [11/100], D Loss: 0.3770, G Loss: 1.7382\n",
      "Epoch [12/100], D Loss: 0.3584, G Loss: 1.9581\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Prepare Data\n",
    "def prepare_data(folder_path, image_size=(32, 32)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img = plt.imread(os.path.join(folder_path, filename))\n",
    "            # Ensure the image has 3 channels\n",
    "            if img.shape[-1] == 4:  # Check for alpha channel\n",
    "                img = img[..., :3]  # Discard the alpha channel\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Resize(image_size)(img)  # Resize to 32x32\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "# Paths\n",
    "folder_5x5 = 'images_5x5'\n",
    "folder_32x32 = 'images_32x32'\n",
    "save_models_folder = 'saved_models'\n",
    "os.makedirs(save_models_folder, exist_ok=True)\n",
    "\n",
    "# Load Data\n",
    "low_res_images = prepare_data(folder_5x5)\n",
    "high_res_images = prepare_data(folder_32x32)\n",
    "\n",
    "# Model Setup\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(low_res_images)):\n",
    "        low_res = low_res_images[i].unsqueeze(0)  # Add batch dimension\n",
    "        high_res = high_res_images[i].unsqueeze(0)\n",
    "\n",
    "        # Create labels to match the output of the discriminator\n",
    "        real_label = torch.ones((1, 1, 4, 4))  # Real label (change size to [1, 1, 4, 4])\n",
    "        fake_label = torch.zeros((1, 1, 4, 4))  # Fake label (change size to [1, 1, 4, 4])\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(high_res)\n",
    "        d_loss_real = criterion(outputs, real_label)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        fake_image = generator(low_res)\n",
    "        outputs = discriminator(fake_image.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_label)\n",
    "        d_loss_fake.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_image)\n",
    "        g_loss = criterion(outputs, real_label)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], D Loss: {d_loss_real.item() + d_loss_fake.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "    \n",
    "    # Save the generator and discriminator models\n",
    "    torch.save(generator.state_dict(), os.path.join(save_models_folder, 'generator.pth'))\n",
    "    torch.save(discriminator.state_dict(), os.path.join(save_models_folder, 'discriminator.pth'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Load the trained generator\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m generator\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_models_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Test the model on image 155\u001b[39;00m\n\u001b[1;32m     57\u001b[0m test_model_on_image(generator, low_res_images, high_res_images, image_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m155\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Updated Testing Function for a specific image (image 155)\n",
    "def test_model_on_image(generator, low_res_images, high_res_images, image_index=155):\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the low-res and high-res images for the specified index\n",
    "        low_res = low_res_images[image_index].unsqueeze(0)\n",
    "        fake_image = generator(low_res).squeeze().cpu().numpy()\n",
    "        real_image = high_res_images[image_index].squeeze().cpu().numpy()\n",
    "        low_res_image = low_res.squeeze().cpu().numpy()\n",
    "\n",
    "        # If the images have 3 channels, convert them to grayscale by averaging the channels\n",
    "        if low_res_image.ndim == 3:\n",
    "            low_res_image = low_res_image.mean(axis=0)  # Convert to grayscale\n",
    "        if fake_image.ndim == 3:\n",
    "            fake_image = fake_image.mean(axis=0)  # Convert to grayscale\n",
    "        if real_image.ndim == 3:\n",
    "            real_image = real_image.mean(axis=0)  # Convert to grayscale\n",
    "\n",
    "        # Calculate PSNR and RMSE\n",
    "        psnr_value = psnr(real_image, fake_image)\n",
    "        rmse_value = np.sqrt(mse(real_image, fake_image))\n",
    "\n",
    "        print(f'PSNR for image {image_index}: {psnr_value:.2f}')\n",
    "        print(f'RMSE for image {image_index}: {rmse_value:.4f}')\n",
    "\n",
    "        # Plot the low-res, real high-res, and generated high-res images\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # Low-res image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(low_res_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Low-Res Image (5x5)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Real high-res image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(real_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Real High-Res Image (32x32)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Generated high-res image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(fake_image, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Generated High-Res Image (32x32)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Load the trained generator\n",
    "generator.load_state_dict(torch.load(os.path.join(save_models_folder, 'generator.pth')))\n",
    "\n",
    "# Test the model on image 155\n",
    "test_model_on_image(generator, low_res_images, high_res_images, image_index=155)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pykrige'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpykrige\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mok\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrdinaryKriging\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Function to perform kriging on an image and interpolate it to a desired resolution\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykrige'"
     ]
    }
   ],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform kriging on an image and interpolate it to a desired resolution\n",
    "def kriging_interpolation(image, new_size):\n",
    "    # Get the current size of the image\n",
    "    current_size = image.shape\n",
    "\n",
    "    # Create grid points for the current image size\n",
    "    x_current = np.linspace(0, current_size[0] - 1, current_size[0])\n",
    "    y_current = np.linspace(0, current_size[1] - 1, current_size[1])\n",
    "    xx_current, yy_current = np.meshgrid(x_current, y_current)\n",
    "\n",
    "    # Flatten the grid and image data\n",
    "    points = np.vstack((xx_current.flatten(), yy_current.flatten())).T\n",
    "    values = image.flatten()\n",
    "\n",
    "    # Create new grid points for the target size\n",
    "    x_new = np.linspace(0, current_size[0] - 1, new_size[0])\n",
    "    y_new = np.linspace(0, current_size[1] - 1, new_size[1])\n",
    "    xx_new, yy_new = np.meshgrid(x_new, y_new)\n",
    "\n",
    "    # Perform kriging interpolation\n",
    "    krig = OrdinaryKriging(xx_current.flatten(), yy_current.flatten(), values, variogram_model='linear')\n",
    "    interpolated_image, _ = krig.execute('grid', x_new, y_new)\n",
    "\n",
    "    return interpolated_image.T  # Transpose to match the original image orientation\n",
    "\n",
    "# Updated Testing Function with Kriging interpolation for specific image (image 155)\n",
    "def test_model_on_image_with_kriging(generator, low_res_images, high_res_images, image_index=155):\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the low-res and high-res images for the specified index\n",
    "        low_res = low_res_images[image_index].unsqueeze(0)\n",
    "        fake_image = generator(low_res).squeeze().cpu().numpy()\n",
    "        real_image = high_res_images[image_index].squeeze().cpu().numpy()\n",
    "        low_res_image = low_res.squeeze().cpu().numpy()\n",
    "\n",
    "        # If the images have 3 channels, convert them to grayscale by averaging the channels\n",
    "        if low_res_image.ndim == 3:\n",
    "            low_res_image = low_res_image.mean(axis=0)  # Convert to grayscale\n",
    "        if fake_image.ndim == 3:\n",
    "            fake_image = fake_image.mean(axis=0)  # Convert to grayscale\n",
    "        if real_image.ndim == 3:\n",
    "            real_image = real_image.mean(axis=0)  # Convert to grayscale\n",
    "\n",
    "        # Perform kriging on the low-res image to interpolate it to 64x64\n",
    "        low_res_kriged = kriging_interpolation(low_res_image, (64, 64))\n",
    "\n",
    "        # Perform kriging on the high-res images to interpolate to 256x256\n",
    "        fake_image_kriged = kriging_interpolation(fake_image, (256, 256))\n",
    "        real_image_kriged = kriging_interpolation(real_image, (256, 256))\n",
    "\n",
    "        # Calculate PSNR and RMSE between the kriged real image and generated image\n",
    "        psnr_value = psnr(real_image_kriged, fake_image_kriged)\n",
    "        rmse_value = np.sqrt(mse(real_image_kriged, fake_image_kriged))\n",
    "\n",
    "        print(f'PSNR for image {image_index} (Kriged): {psnr_value:.2f}')\n",
    "        print(f'RMSE for image {image_index} (Kriged): {rmse_value:.4f}')\n",
    "\n",
    "        # Plot the kriged low-res, real high-res, and generated high-res images\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Kriged low-res image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(low_res_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Low-Res Image (5x5 Kriged to 64x64)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Kriged real high-res image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(real_image_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Real High-Res Image (32x32 Kriged to 256x256)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Kriged generated high-res image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(fake_image_kriged, cmap='viridis', interpolation='none')\n",
    "        plt.title(f'Generated High-Res Image (32x32 Kriged to 256x256)\\nImage {image_index}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test the model on image 155 with kriging interpolation\n",
    "test_model_on_image_with_kriging(generator, low_res_images, high_res_images, image_index=155)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
